{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQspTMFdNEQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "09192e8a-2380-40df-d581-15b75c054348"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as T\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Sequential, Model, load_model, save_model\n",
        "from keras.layers.core import Dense, Lambda, Activation\n",
        "from keras.layers import Embedding, Input, Dense, merge, Reshape,  Flatten, Dropout\n",
        "from keras.optimizers import Adagrad, Adam, SGD, RMSprop, Adamax\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Multiply, Concatenate\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from time import time\n",
        "import multiprocessing as mp\n",
        "import sys\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0f3542ccf1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: No module named statistics",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj3a8Xd9mNXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVhF4SPkmaCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RATING_DATA_FILE_TRAIN = 'u1.base'\n",
        "RATING_DATA_FILE_TEST = 'u1.test'\n",
        "RATING_DATA_GEN_FILE = 'u_gen.data'\n",
        "RATINGS_CSV_FILE_NORM = 'u_norm.data'\n",
        "RATINGS_GEN_CSV_FILE = 'u_genr.data'\n",
        "MODEL_WEIGHTS_FILE = 'u_emb_weights.h5'\n",
        "MODEL_WEIGHTS_FILE_CORE = 'u_emb_weights'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewaz10iUp9vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_file_import_train = drive.CreateFile({'id':'1smKszlPQlT03Bbi7yLRIDIkd0c-XS-Y5'})\n",
        "rating_file_import_train.GetContentFile(RATING_DATA_FILE_TRAIN)\n",
        "rating_file_import_test = drive.CreateFile({'id':'1dxlfTQJiQ5MyewGyhk7Y4A9mETdnjknf'})\n",
        "rating_file_import_test.GetContentFile(RATING_DATA_FILE_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOdshg9Ss0l8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4c5b99d-f82a-45b6-a84c-9de83ac484bb"
      },
      "source": [
        "ratings = pd.read_csv(RATING_DATA_FILE_TRAIN, \n",
        "                    sep='\\t', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['userid', 'movieid', 'rating', 'timestamp'])\n",
        "max_userid = ratings['userid'].drop_duplicates().max()\n",
        "max_movieid = ratings['movieid'].drop_duplicates().max()\n",
        "ratings['user_emb_id'] = ratings['userid'] - 1\n",
        "ratings['movie_emb_id'] = ratings['movieid'] - 1\n",
        "print(str(len(ratings))+' ratings loaded')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000 ratings loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Hih6Xl4gxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "150a0fa3-0b39-4637-d413-80ee02114b15"
      },
      "source": [
        "test_ratings = pd.read_csv(RATING_DATA_FILE_TEST, \n",
        "                    sep='\\t', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['userid', 'movieid', 'rating', 'timestamp'])\n",
        "test_ratings['user_emb_id'] = test_ratings['userid'] - 1\n",
        "test_ratings['movie_emb_id'] = test_ratings['movieid'] - 1\n",
        "print(str(len(test_ratings))+' ratings loaded')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 ratings loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MyhiMt0tCUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ncf_model(num_users, num_items, latent_dim,hidden_dim,do):\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "\n",
        "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
        "    \n",
        "    # Crucial to flatten an embedding vector!\n",
        "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    \n",
        "    # Element-wise product of user and item embeddings\n",
        "    conc = Concatenate()([user_latent, item_latent])\n",
        "    drop = Dropout(0.5)(conc)\n",
        "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
        "    drop2  = Dropout(do)(hid1)\n",
        "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
        "    \n",
        "    \n",
        "    model = Model(input=[user_input, item_input], output=prediction)\n",
        "    print(\"ncf model\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6STtcDitjQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NCF_model\n",
        "K_LATENT\n",
        "hidden_dim\n",
        "do\n",
        "\n",
        "def set_ncf_model(parameter_hidden_dim, parameter_loss,parameter_optimizer,):\n",
        "  K_LATENT = 20\n",
        "  hidden_dim = parameter_hidden_dim\n",
        "  do = 0.5\n",
        "  NCF_model = get_ncf_model(max_userid,max_movieid,K_LATENT,hidden_dim,do)\n",
        "  NCF_model.compile(loss=parameter_loss,optimizer=parameter_optimizer,metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tAu7I_Evoql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "ba8a53e4-ba0a-47e8-89f7-d3c3a60d7d44"
      },
      "source": [
        "\n",
        "set_ncf_model(20,'mse','Adamax')\n",
        "Users = ratings['user_emb_id'].values\n",
        "Movies = ratings['movie_emb_id'].values\n",
        "Ratings = ratings['rating'].values"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ncf model\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 20)        18860       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "item_embedding (Embedding)      (None, 1, 20)        33640       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 20)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 20)           0           item_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 40)           0           flatten_11[0][0]                 \n",
            "                                                                 flatten_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 20)           820         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 20)           0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            21          dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 53,341\n",
            "Trainable params: 53,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"pr..., inputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3auwcrmxvXJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "8e293dc9-7ebf-4b8f-a3cb-c1ec946bafa6"
      },
      "source": [
        "callbacks_ncf = [EarlyStopping('val_loss', patience=30), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncf_'+str(do)+'_'+str(K_LATENT)+'_'+str(hidden_dim)+'.h5', save_best_only=True)]\n",
        "history_history_ncf = NCF_model.fit([Users, Movies], Ratings, nb_epoch=60, validation_split=.1, verbose=1, callbacks=callbacks_ncf, batch_size = 32)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 56000 samples, validate on 24000 samples\n",
            "Epoch 1/60\n",
            " 3456/56000 [>.............................] - ETA: 2s - loss: 0.8052 - mean_absolute_error: 0.7043"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "56000/56000 [==============================] - 3s 53us/step - loss: 0.7986 - mean_absolute_error: 0.7034 - val_loss: 0.8901 - val_mean_absolute_error: 0.7658\n",
            "Epoch 2/60\n",
            "56000/56000 [==============================] - 3s 52us/step - loss: 0.8005 - mean_absolute_error: 0.7049 - val_loss: 0.8915 - val_mean_absolute_error: 0.7671\n",
            "Epoch 3/60\n",
            "56000/56000 [==============================] - 3s 52us/step - loss: 0.8017 - mean_absolute_error: 0.7050 - val_loss: 0.8953 - val_mean_absolute_error: 0.7684\n",
            "Epoch 4/60\n",
            "56000/56000 [==============================] - 3s 53us/step - loss: 0.7996 - mean_absolute_error: 0.7042 - val_loss: 0.8985 - val_mean_absolute_error: 0.7714\n",
            "Epoch 5/60\n",
            "56000/56000 [==============================] - 3s 53us/step - loss: 0.8003 - mean_absolute_error: 0.7049 - val_loss: 0.9030 - val_mean_absolute_error: 0.7750\n",
            "Epoch 6/60\n",
            "56000/56000 [==============================] - 3s 51us/step - loss: 0.7989 - mean_absolute_error: 0.7046 - val_loss: 0.9003 - val_mean_absolute_error: 0.7728\n",
            "Epoch 7/60\n",
            "56000/56000 [==============================] - 3s 51us/step - loss: 0.7962 - mean_absolute_error: 0.7023 - val_loss: 0.9070 - val_mean_absolute_error: 0.7763\n",
            "Epoch 8/60\n",
            "56000/56000 [==============================] - 3s 52us/step - loss: 0.8001 - mean_absolute_error: 0.7043 - val_loss: 0.9003 - val_mean_absolute_error: 0.7721\n",
            "Epoch 9/60\n",
            "56000/56000 [==============================] - 3s 54us/step - loss: 0.7966 - mean_absolute_error: 0.7028 - val_loss: 0.8933 - val_mean_absolute_error: 0.7662\n",
            "Epoch 10/60\n",
            "56000/56000 [==============================] - 3s 53us/step - loss: 0.7980 - mean_absolute_error: 0.7034 - val_loss: 0.9049 - val_mean_absolute_error: 0.7745\n",
            "Epoch 11/60\n",
            "56000/56000 [==============================] - 3s 55us/step - loss: 0.7978 - mean_absolute_error: 0.7029 - val_loss: 0.9011 - val_mean_absolute_error: 0.7717\n",
            "Epoch 12/60\n",
            "56000/56000 [==============================] - 3s 53us/step - loss: 0.7943 - mean_absolute_error: 0.7009 - val_loss: 0.9090 - val_mean_absolute_error: 0.7780\n",
            "Epoch 13/60\n",
            "14272/56000 [======>.......................] - ETA: 1s - loss: 0.7897 - mean_absolute_error: 0.6986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0c3ff7269adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks_ncf = [EarlyStopping('val_loss', patience=30), \n\u001b[1;32m      2\u001b[0m              ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncf_'+str(do)+'_'+str(K_LATENT)+'_'+str(hidden_dim)+'.h5', save_best_only=True)]\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory_history_ncf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNCF_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUsers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMovies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRatings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_ncf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq3LaZlbzPUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1199
        },
        "outputId": "466d9483-f011-4484-adbb-4f1238c1ddb4"
      },
      "source": [
        "\n",
        "test_Users = test_ratings['user_emb_id'].values\n",
        "test_Movies = test_ratings['movie_emb_id'].values\n",
        "test_Ratings = test_ratings['rating'].values\n",
        "predict=NCF_model.predict([test_Users,test_Movies])\n",
        "df_predict=pd.DataFrame(data=predict,columns=['prediction'])\n",
        "df_predict['ratings'] = test_Ratings\n",
        "\n",
        "# print(df_predict)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main method - 0.7928911358368012\n",
            "       prediction  ratings\n",
            "0        3.846047        5\n",
            "1        4.192070        3\n",
            "2        4.560959        5\n",
            "3        4.204177        5\n",
            "4        3.296424        3\n",
            "5        4.012165        4\n",
            "6        4.472283        4\n",
            "7        3.582150        3\n",
            "8        2.974776        2\n",
            "9        3.550973        3\n",
            "10       3.534667        4\n",
            "11       1.693192        2\n",
            "12       3.341532        4\n",
            "13       3.325302        5\n",
            "14       3.932510        4\n",
            "15       3.280835        3\n",
            "16       3.633845        4\n",
            "17       3.120405        3\n",
            "18       3.284105        3\n",
            "19       4.464338        4\n",
            "20       4.391423        5\n",
            "21       3.987499        4\n",
            "22       3.166443        3\n",
            "23       4.570510        5\n",
            "24       3.905074        4\n",
            "25       2.798226        3\n",
            "26       3.968210        3\n",
            "27       3.821422        3\n",
            "28       3.019819        4\n",
            "29       3.398594        3\n",
            "...           ...      ...\n",
            "19970    2.915899        3\n",
            "19971    3.424267        3\n",
            "19972    3.108876        4\n",
            "19973    3.478194        2\n",
            "19974    3.011983        2\n",
            "19975    2.895822        4\n",
            "19976    2.811963        2\n",
            "19977    3.847225        5\n",
            "19978    3.743535        3\n",
            "19979    3.590707        4\n",
            "19980    3.048202        3\n",
            "19981    3.373337        3\n",
            "19982    3.648880        3\n",
            "19983    3.221785        1\n",
            "19984    3.395927        3\n",
            "19985    3.536423        4\n",
            "19986    4.645817        4\n",
            "19987    4.688335        5\n",
            "19988    3.967848        4\n",
            "19989    4.437103        4\n",
            "19990    3.996138        4\n",
            "19991    3.237815        4\n",
            "19992    3.957882        4\n",
            "19993    3.417284        3\n",
            "19994    3.799775        4\n",
            "19995    4.051175        4\n",
            "19996    3.857971        4\n",
            "19997    3.375079        3\n",
            "19998    3.580059        3\n",
            "19999    3.484361        5\n",
            "\n",
            "[20000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO6lNf3cGNqP",
        "colab_type": "text"
      },
      "source": [
        "according to the first "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovs5Hn-ZEqV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1781
        },
        "outputId": "58b55aa8-da64-4a06-b583-d52677fedd4c"
      },
      "source": [
        "print('main method - '+str(sum(history_history_ncf.history['val_mean_absolute_error'])/len(history_history_ncf.history['val_mean_absolute_error'])))\n",
        "set_ncf_model(16,'mse','Adamax')\n",
        "callbacks_ncf = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncf_'+str(do)+'_'+str(K_LATENT)+'_'+str(hidden_dim)+'.h5', save_best_only=True)]\n",
        "history_history_ncf = NCF_model.fit([Users, Movies], Ratings, nb_epoch=60, validation_split=.1, verbose=0, callbacks=callbacks_ncf, batch_size = 32)\n",
        "predict=NCF_model.predict([test_Users,test_Movies])\n",
        "df_predict=pd.DataFrame(data=predict,columns=['prediction'])\n",
        "df_predict['ratings'] = test_Ratings\n",
        "print('second method hidden layer size=16 - '+str(sum(history_history_ncf.history['val_mean_absolute_error'])/len(history_history_ncf.history['val_mean_absolute_error'])))\n",
        "set_ncf_model(20,'mse','sgd')\n",
        "callbacks_ncf = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncf_'+str(do)+'_'+str(K_LATENT)+'_'+str(hidden_dim)+'.h5', save_best_only=True)]\n",
        "history_history_ncf = NCF_model.fit([Users, Movies], Ratings, nb_epoch=60, validation_split=.1, verbose=0, callbacks=callbacks_ncf, batch_size = 32)\n",
        "predict=NCF_model.predict([test_Users,test_Movies])\n",
        "df_predict=pd.DataFrame(data=predict,columns=['prediction'])\n",
        "df_predict['ratings'] = test_Ratings\n",
        "print('third method optimizer=SGD - '+str(sum(history_history_ncf.history['val_mean_absolute_error'])/len(history_history_ncf.history['val_mean_absolute_error'])))\n",
        "set_ncf_model(20,'mape','Adamax')\n",
        "callbacks_ncf = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncf_'+str(do)+'_'+str(K_LATENT)+'_'+str(hidden_dim)+'.h5', save_best_only=True)]\n",
        "history_history_ncf = NCF_model.fit([Users, Movies], Ratings, nb_epoch=60, validation_split=.1, verbose=0, callbacks=callbacks_ncf, batch_size = 32)\n",
        "predict=NCF_model.predict([test_Users,test_Movies])\n",
        "df_predict=pd.DataFrame(data=predict,columns=['prediction'])\n",
        "df_predict['ratings'] = test_Ratings\n",
        "print('fourth method loss function=mean absolute precentage error - '+str(sum(history_history_ncf.history['val_mean_absolute_error'])/len(history_history_ncf.history['val_mean_absolute_error'])))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main method - 0.8669673980308903\n",
            "ncf model\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 20)        18860       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "item_embedding (Embedding)      (None, 1, 20)        33640       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 20)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 20)           0           item_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 40)           0           flatten_15[0][0]                 \n",
            "                                                                 flatten_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 16)           656         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16)           0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            17          dropout_16[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 53,173\n",
            "Trainable params: 53,173\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"pr..., inputs=[<tf.Tenso...)`\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "second method hidden layer size=16 - 0.8759517161498467\n",
            "ncf model\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 20)        18860       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "item_embedding (Embedding)      (None, 1, 20)        33640       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_17 (Flatten)            (None, 20)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_18 (Flatten)            (None, 20)           0           item_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 40)           0           flatten_17[0][0]                 \n",
            "                                                                 flatten_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 20)           820         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 20)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            21          dropout_18[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 53,341\n",
            "Trainable params: 53,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "third method optimizer=SGD - 0.8805747488845479\n",
            "ncf model\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 20)        18860       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "item_embedding (Embedding)      (None, 1, 20)        33640       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 20)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_20 (Flatten)            (None, 20)           0           item_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 40)           0           flatten_19[0][0]                 \n",
            "                                                                 flatten_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 20)           820         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 20)           0           dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            21          dropout_20[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 53,341\n",
            "Trainable params: 53,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fourth method loss function=mean absolute precentage error - 0.8833961687413128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouVF8_1LOkaP",
        "colab_type": "text"
      },
      "source": [
        "The first method had shown the best results in based on the same parameters as the other method except the optimizer,loss function and the hidden dimentions.\n",
        "From our research in the web we have concluded that the adamax optimizer is considered to be the best optimizer for this spessific problem. In addition the mse loss function has the closest aproximation to the real error value.As for the number of nodes in the hidden layer there isn't a good explanation for this spesific number, but through trial and error we deducted that 20 nodes show a decent result.\n"
      ]
    }
  ]
}